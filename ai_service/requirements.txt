# Core dependencies
fastapi>=0.104.1
uvicorn>=0.24.0
openai>=1.3.0
#llama-cpp-python>=0.2.0
pydantic>=2.5.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0

# Monitoring and logging
prometheus-client>=0.19.0
prometheus-fastapi-instrumentator>=6.1.0
structlog>=24.1.0
python-json-logger>=2.0.7

# Cache and rate limiting
redis>=5.0.1
tenacity>=8.2.3

# HTTP client
httpx>=0.25.0

# NLP and ML
spacy>=3.7.2
transformers>=4.36.0
--find-links https://download.pytorch.org/whl/torch_stable.html
torch==2.3.1+cpu
# Removing llama-cpp-python temporarily until we have proper CPU build setup