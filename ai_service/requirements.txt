fastapi>=0.104.1
uvicorn>=0.24.0
openai>=1.3.0
llama-cpp-python>=0.2.0
pydantic>=2.5.0
prometheus-client>=0.19.0
prometheus-fastapi-instrumentator>=6.1.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
structlog>=24.1.0
python-json-logger>=2.0.7
redis>=5.0.1  # For rate limiting
tenacity>=8.2.3
httpx>=0.25.0
transformers>=4.36.0  # For text processing
torch>=2.1.0  # For local model inference 